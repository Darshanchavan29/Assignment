{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b504c3-464d-45f7-aa99-d55823139c46",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e32959-6e51-4fd0-9719-6efe5b67aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWeb scrapping also known as web data Extraction which formally known as process of obtaning & structuring data from \\nweb using intelligent automation. It can be used to retrieve hundreds, millions or billions of data points from internet\\neffortlessly. \\n\\nBasicaly of two Parts: \\nweb Crawling (in this browses internet to index & search for content by following links like google crawler bot which categorizes webs)\\nWeb scrapper (In this Data extraction from a webpage or specially designed APIs which gave us access to scrap limited or specific data)\\n\\n\\nWeb Scraping used in soo many field whether it could be history price comparision , sentiment analysis like people what now a days buying or eating \\nextracting info from social media regarding pattern behaviour of it's user which can be used for promotion, political agenda setting and categorization of\\nimages, webpages\\n\\nAreas where Web scraping used: \\ncollecting historical data for trend prediction and future analysis \\ncollecting customers or client information from websites and social media so which help marketers and salespeople\\ncurrency exchange rates, job boards, weather forcasting are some other usecase\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Web scrapping also known as web data Extraction which formally known as process of obtaning & structuring data from \n",
    "web using intelligent automation. It can be used to retrieve hundreds, millions or billions of data points from internet\n",
    "effortlessly. \n",
    "\n",
    "Basicaly of two Parts: \n",
    "web Crawling (in this browses internet to index & search for content by following links like google crawler bot which categorizes webs)\n",
    "Web scrapper (In this Data extraction from a webpage or specially designed APIs which gave us access to scrap limited or specific data)\n",
    "\n",
    "\n",
    "Web Scraping used in soo many field whether it could be history price comparision , sentiment analysis like people what now a days buying or eating \n",
    "extracting info from social media regarding pattern behaviour of it's user which can be used for promotion, political agenda setting and categorization of\n",
    "images, webpages\n",
    "\n",
    "Areas where Web scraping used: \n",
    "collecting historical data for trend prediction and future analysis \n",
    "collecting customers or client information from websites and social media so which help marketers and salespeople\n",
    "currency exchange rates, job boards, weather forcasting are some other usecase\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed5f98-f6bd-416e-8743-a21f35dc7f9d",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aca396c-46fb-4e47-8f89-6d5cbf8e38e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThere could be several method involved in we scraping which includes manual selection and automated crawling \\nweb pages using pre-programmed scraping applications.\\nHTTP request to extract data from the websites all this by doing task automated \\nDOM parsing, text pattern matching and computer vision web page analysi are some other method used in web scraping\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "There could be several method involved in web scraping which includes manual selection and automated crawling \n",
    "web pages using pre-programmed scraping applications.\n",
    "HTTP request to extract data from the websites all this by doing task automated \n",
    "DOM parsing, text pattern matching and computer vision web page analysi are some other method used in web scraping\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09632fa-6d65-4f44-ad0e-216d8bc37bcd",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034b2f85-e2ed-40c5-9704-8f1561bdb688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nBeautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files.\\nIt creates a parser tree from page source code that can be used to extract data in a hierarchical and more readable manner.\\nBeautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. \\nIt is a tool for web scraping that helps you clean up and parser the documents\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files.\n",
    "It creates a parser tree from page source code that can be used to extract data in a hierarchical and more readable manner.\n",
    "Beautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. \n",
    "It is a tool for web scraping that helps you clean up and parser the documents\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be9ff0-5f87-47aa-9ef8-47f81b826eee",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9227b2e9-72af-45c8-a682-3eafcf79358f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFlask is used in web scraping projects because it is a lightweight framework that is easy to learn and use. \\nIt is also more explicit than Django’s framework, which makes it easier to understand and implement a simple web application.\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Flask is used in web scraping projects because it is a lightweight framework that is easy to learn and use. \n",
    "It is also more explicit than Django’s framework, which makes it easier to understand and implement a simple web application.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae32365-ede8-4298-b482-f5f9717380ba",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c63485-c1db-42bb-9fd5-ffc48308d1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn our AWS project we used two AWS service named as: \\n- code pipeline \\n- Bean Stalk \\n\\nCode Pipeline: It is a continues  delivery service we can use to model, visualize, and automate the steps required\\nto release your software. We can quickly model and configure the different stages of a software release process. \\nCodePipeline automates the steps required to release your software changes continuously.\\n\\nBean stalk or AWS Elastic Beanstalk is a conputer service that makes it easier for developer to quickly deploy and manage\\napplciation that they uploaded to AWS cloud \\nbeanstalk handle the configuration and provision for them by reducing management complexity without restricting choice or control\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In our AWS project we used two AWS service named as: \n",
    "- code pipeline \n",
    "- Bean Stalk \n",
    "\n",
    "Code Pipeline: It is a continues  delivery service we can use to model, visualize, and automate the steps required\n",
    "to release your software. We can quickly model and configure the different stages of a software release process. \n",
    "CodePipeline automates the steps required to release your software changes continuously.\n",
    "\n",
    "Bean stalk or AWS Elastic Beanstalk is a conputer service that makes it easier for developer to quickly deploy and manage\n",
    "applciation that they uploaded to AWS cloud \n",
    "beanstalk handle the configuration and provision for them by reducing management complexity without restricting choice or control\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6169d0-c1f3-417a-b498-2898f2eb64d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
